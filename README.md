# Song-to-Video Dataset
Song-to-video dataset is used to facilitate the research of song-to-video translation (S2VT) work, which includes song and paired song lyrics, videos and labels. We also publish the used footage repository.

## Datasets
Download our footage repository and video dataset from the link: https://drive.google.com/drive/folders/1bELhKX8vrPN4_hX94ZwUmpgLxRChmm4P?usp=sharing. For the footage, there are some files in this drive, rest files will be released after opening due to the capacity limitations of drive.
| Filename  |  Description |
|  ------  | ------- |
|  labels |  Annotated video dataset according to three metrics for training classifiers |
|  lyric_files  |  Song and correponding song lyrics to generate videos |
|  footage repository |  A large collection of shots  |
|  video dataset |  Generated videos using Random Selection method (referred to our paper) based on lyric files |

## Usage
Input song and corresponding song lyrics, the video is automatically generated by the system. The used shots in the video are retrieved from collected footage repository by the large-scale multimodal pre-training model [WenLan](https://github.com/chuhaojin/WenLan-api-document).

## Demo Video
Please see the video examples (https://youtu.be/XxgNcPhNQNY, https://youtu.be/LF7CQ1WEiRk, https://youtu.be/YWYgWZaa_Cc) generated by our proposed method based on this dataset.
